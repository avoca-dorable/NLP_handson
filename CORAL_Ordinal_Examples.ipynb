{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CORAL Ordinal Examples.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avoca-dorable/NLP_handson/blob/main/CORAL_Ordinal_Examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcT_VpWpT1Kf"
      },
      "source": [
        "# Ordinal classification in Tensorflow Keras \n",
        "\n",
        "This notebook uses MNIST hand-written digits and Amazon reviews as a examples of ordinal classification, using the coral-ordinal package for Tensorflow Keras.\n",
        "\n",
        "\n",
        "**Acknowledgments**: This notebook is based in part on PyTorch source code written by Sebastian Rashka [in this notebook](https://github.com/Raschka-research-group/coral-cnn/blob/master/coral-implementation-recipe.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QsCIIgoFOkr"
      },
      "source": [
        "## Installation\n",
        "\n",
        "With pip you can either install the latest source code from GitHub or the stable version of the module on pypi.org\n",
        "\n",
        "# View data\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2HQ89oVs5TS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "526fa035-183d-4cc3-eddb-ee8dff959998"
      },
      "source": [
        "# Use Tensorflow 2.2 rather than 2.3 or a later version.\n",
        "# To support TF 2.3 we need to try switching \"convert_to_tensor_v2\" to \"convert_to_tensor\" in loss.py\n",
        "# Per https://github.com/ck37/coral-ordinal/issues/1\n",
        "# !pip install -q tensorflow==2.2\n",
        "\n",
        "# Install stable version from pypi.org\n",
        "#!pip install coral-ordinal -q --force-reinstall --no-deps\n",
        "\n",
        "# Install source package from GitHub\n",
        "!pip install --force-reinstall --no-deps git+https://github.com/ck37/coral-ordinal/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/ck37/coral-ordinal/\n",
            "  Cloning https://github.com/ck37/coral-ordinal/ to /tmp/pip-req-build-w386bvze\n",
            "  Running command git clone -q https://github.com/ck37/coral-ordinal/ /tmp/pip-req-build-w386bvze\n",
            "Building wheels for collected packages: coral-ordinal\n",
            "  Building wheel for coral-ordinal (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for coral-ordinal: filename=coral_ordinal-0.1.9.dev0-py3-none-any.whl size=14610 sha256=daa9a7b13ff7168a99fbd8f2ec791ad82a09489f861b6cf1075f6ed55489fddd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qvv7_3vf/wheels/01/d9/85/8a6675507c6e6f1f9b890510f5b5ebd1fac5220ba0fc0893d7\n",
            "Successfully built coral-ordinal\n",
            "Installing collected packages: coral-ordinal\n",
            "Successfully installed coral-ordinal-0.1.9.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Xemf4TAtrJC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2495d51-a5a3-4c25-834e-22c671ac644c"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"Tensorflow version\", tf.__version__)\n",
        "\n",
        "import coral_ordinal as coral\n",
        "print(\"CORAL Ordinal version:\", coral.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version 2.8.0\n",
            "CORAL Ordinal version: 0.1.9.dev\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rq0mT2yYucrx"
      },
      "source": [
        "## MNIST toy example\n",
        "\n",
        "This outcome is not actually ordinal, it's categorical. We're just using it as a toy example to show how the different components are used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSOcGJBJG1Tr"
      },
      "source": [
        "##########################\n",
        "### SETTINGS\n",
        "##########################\n",
        "\n",
        "# Hyperparameters\n",
        "random_seed = 1 # Not yet used\n",
        "learning_rate = 0.05\n",
        "batch_size = 128\n",
        "num_epochs = 2\n",
        "\n",
        "# Architecture\n",
        "NUM_CLASSES = 10"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NooIWGJbGR2u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0756557-0ca5-48b5-8573-59954adefa2f"
      },
      "source": [
        "# Fetch and format the mnist data\n",
        "(mnist_images, mnist_labels), (mnist_images_test, mnist_labels_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Split off a validation dataset for early stopping\n",
        "from sklearn import model_selection\n",
        "mnist_images, mnist_images_val, mnist_labels, mnist_labels_val = \\\n",
        "  model_selection.train_test_split(mnist_images, mnist_labels, test_size = 5000, random_state = 1)\n",
        "\n",
        "print(\"Shape of training images:\", mnist_images.shape)\n",
        "print(\"Shape of training labels:\", mnist_labels.shape)\n",
        "\n",
        "print(\"Shape of test images:\", mnist_images_test.shape)\n",
        "print(\"Shape of test labels:\", mnist_labels_test.shape)\n",
        "\n",
        "print(\"Shape of validation images:\", mnist_images_val.shape)\n",
        "print(\"Shape of validation labels:\", mnist_labels_val.shape)\n",
        "\n",
        "# Also rescales to 0-1 range.\n",
        "dataset = tf.data.Dataset.from_tensor_slices(\n",
        "  (tf.cast(mnist_images[..., tf.newaxis] / 255, tf.float32),\n",
        "   tf.cast(mnist_labels, tf.int64)))\n",
        "dataset = dataset.shuffle(1000).batch(batch_size)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "  (tf.cast(mnist_images_test[..., tf.newaxis] / 255, tf.float32),\n",
        "   tf.cast(mnist_labels_test, tf.int64)))\n",
        "#test_dataset = test_dataset.shuffle(1000).batch(batch_size)\n",
        "# Here we do not shuffle the test dataset.\n",
        "test_dataset = test_dataset.batch(batch_size)\n",
        "\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "  (tf.cast(mnist_images_val[..., tf.newaxis] / 255, tf.float32),\n",
        "   tf.cast(mnist_labels_val, tf.int64)))\n",
        "val_dataset = val_dataset.shuffle(1000).batch(batch_size)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "Shape of training images: (55000, 28, 28)\n",
            "Shape of training labels: (55000,)\n",
            "Shape of test images: (10000, 28, 28)\n",
            "Shape of test labels: (10000,)\n",
            "Shape of validation images: (5000, 28, 28)\n",
            "Shape of validation labels: (5000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAg-gWZED1mR"
      },
      "source": [
        "### Simple MLP model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9MF55Xz53rx"
      },
      "source": [
        "Now we create a simple multi-layer perceptron model so that we can apply the ordinal output layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-ozv44W52Ti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c71d29d-cf5d-467b-93c4-c3ea8570e6b4"
      },
      "source": [
        "def create_model(num_classes):\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Flatten(input_shape = (28, 28, )))\n",
        "  model.add(tf.keras.layers.Dense(128, activation = \"relu\"))\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "  model.add(tf.keras.layers.Dense(32, activation = \"relu\"))\n",
        "  model.add(tf.keras.layers.Dropout(0.1))\n",
        "  # Ordinal output layer with a certain number of classes / ranks / labels.\n",
        "  # No activation function specified so this will output cumulative logits.\n",
        "  model.add(coral.CoralOrdinal(num_classes))\n",
        "  return model\n",
        "\n",
        "model = create_model(NUM_CLASSES)\n",
        "\n",
        "# Note that the model generates 1 fewer outputs than the number of classes. \n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " coral_ordinal (CoralOrdinal  (None, 9)                41        \n",
            " )                                                               \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 104,649\n",
            "Trainable params: 104,649\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YAftcr9wxTu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6c2826e-71d5-4ddb-9f46-48aac537b72f"
      },
      "source": [
        "# Or a functional API version\n",
        "def create_model2(num_classes):\n",
        "  inputs = tf.keras.Input(shape = (28, 28, ))\n",
        "\n",
        "  x = tf.keras.layers.Flatten()(inputs)\n",
        "  x = tf.keras.layers.Dense(128, activation = \"relu\")(x)\n",
        "  x = tf.keras.layers.Dropout(0.2)(x)\n",
        "  x = tf.keras.layers.Dense(32, activation = \"relu\")(x)\n",
        "  x = tf.keras.layers.Dropout(0.1)(x)\n",
        "\n",
        "  # Ordinal output layer with a certain number of classes / ranks / labels.\n",
        "  # No activation function specified so this will output cumulative logits.\n",
        "  outputs = coral.CoralOrdinal(num_classes)(x)\n",
        "\n",
        "  model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
        "\n",
        "  return model\n",
        "\n",
        "model = create_model2(NUM_CLASSES)\n",
        "\n",
        "# Note that the model generates 1 fewer outputs than the number of classes. \n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 28, 28)]          0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " coral_ordinal_1 (CoralOrdin  (None, 9)                41        \n",
            " al)                                                             \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 104,649\n",
            "Trainable params: 104,649\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUIADdPeF2w6",
        "outputId": "eb41e627-82a6-4d12-9537-6be584b2297d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(lr = learning_rate),\n",
        "              loss = coral.OrdinalCrossEntropy(num_classes = NUM_CLASSES),\n",
        "              metrics = [coral.MeanAbsoluteErrorLabels()])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as_rVDyAJurK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b4358ad-d200-4494-d1ab-fbfe54dd44a1"
      },
      "source": [
        "%%time\n",
        "\n",
        "# This takes about 5 minutes on CPU, 2.5 minutes on GPU.\n",
        "history = model.fit(dataset, epochs = 5, validation_data = val_dataset,\n",
        "                    callbacks = [tf.keras.callbacks.EarlyStopping(patience = 3, restore_best_weights = True)])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "430/430 [==============================] - 7s 6ms/step - loss: 3.6455 - mean_absolute_error_labels: 1.5000 - val_loss: 2.3776 - val_mean_absolute_error_labels: 0.9377\n",
            "Epoch 2/5\n",
            "430/430 [==============================] - 2s 5ms/step - loss: 2.3902 - mean_absolute_error_labels: 0.9588 - val_loss: 1.9511 - val_mean_absolute_error_labels: 0.6676\n",
            "Epoch 3/5\n",
            "430/430 [==============================] - 2s 5ms/step - loss: 2.1756 - mean_absolute_error_labels: 0.8211 - val_loss: 1.7845 - val_mean_absolute_error_labels: 0.5980\n",
            "Epoch 4/5\n",
            "430/430 [==============================] - 2s 5ms/step - loss: 2.0754 - mean_absolute_error_labels: 0.7800 - val_loss: 1.8114 - val_mean_absolute_error_labels: 0.6420\n",
            "Epoch 5/5\n",
            "430/430 [==============================] - 2s 6ms/step - loss: 2.0872 - mean_absolute_error_labels: 0.7875 - val_loss: 1.7461 - val_mean_absolute_error_labels: 0.5586\n",
            "CPU times: user 17.4 s, sys: 2.37 s, total: 19.7 s\n",
            "Wall time: 22.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i--Xhzu8D6Mb"
      },
      "source": [
        "### Test set evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epv3NVRmJ1gt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7146c53f-4ee0-4d0b-96c9-f9afbed851cc"
      },
      "source": [
        "# Evaluate on test dataset.\n",
        "model.evaluate(test_dataset)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 0s 4ms/step - loss: 1.7228 - mean_absolute_error_labels: 0.5466\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7227572202682495, 0.5465783476829529]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list(test_dataset.as_numpy_iterator())[0]"
      ],
      "metadata": {
        "id": "5mtaxFdsRG_x"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pfaK4doXvcS"
      },
      "source": [
        "### Cumulative logits to probabilities\n",
        "\n",
        "We can convert the cumulative logit output of the layer into the probability estimate for each ordinal label. This can then be used to calculate other metrics like accuracy or mean absolute error.\n",
        "\n",
        "Notice that the probability distribution for each observation is unimodal, which is what we want for an ordinal outcome variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MAi4QxZyA2_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "704007e7-ba21-4dd6-a20b-0192c5801ca7"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "print(\"Predict on test dataset\")\n",
        "\n",
        "# Note that these are ordinal (cumulative) logits, not probabilities or regular logits.\n",
        "ordinal_logits = model.predict(test_dataset)\n",
        "\n",
        "# Convert from logits to label probabilities. This is initially a tensorflow tensor.\n",
        "tensor_probs = coral.ordinal_softmax(ordinal_logits)\n",
        "\n",
        "# Convert the tensor into a pandas dataframe.\n",
        "probs_df = pd.DataFrame(tensor_probs.numpy())\n",
        "\n",
        "probs_df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict on test dataset\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1             2             3             4             5  \\\n",
              "0  0.000002  0.000639  3.687680e-03  1.130116e-02  2.431327e-02  4.502517e-02   \n",
              "1  0.000927  0.219075  4.366043e-01  2.181347e-01  7.344209e-02  2.791687e-02   \n",
              "2  0.022289  0.851616  1.052545e-01  1.504655e-02  3.574800e-03  1.223628e-03   \n",
              "3  0.999969  0.000031  8.642356e-08  1.085965e-08  2.531914e-09  8.624932e-10   \n",
              "4  0.000060  0.017802  9.189916e-02  2.007258e-01  2.307799e-01  1.835133e-01   \n",
              "\n",
              "              6             7             8             9  \n",
              "0  1.225838e-01  2.842679e-01  3.513567e-01  1.568233e-01  \n",
              "1  1.529375e-02  6.262463e-03  1.921075e-03  4.226996e-04  \n",
              "2  6.423246e-04  2.575669e-04  7.839075e-05  1.720976e-05  \n",
              "3  4.519073e-10  1.810481e-10  5.508360e-11  1.209181e-11  \n",
              "4  1.565654e-01  8.350112e-02  2.863754e-02  6.515471e-03  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85f7ecc5-be37-4a5a-a4dd-893895175ebb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000639</td>\n",
              "      <td>3.687680e-03</td>\n",
              "      <td>1.130116e-02</td>\n",
              "      <td>2.431327e-02</td>\n",
              "      <td>4.502517e-02</td>\n",
              "      <td>1.225838e-01</td>\n",
              "      <td>2.842679e-01</td>\n",
              "      <td>3.513567e-01</td>\n",
              "      <td>1.568233e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000927</td>\n",
              "      <td>0.219075</td>\n",
              "      <td>4.366043e-01</td>\n",
              "      <td>2.181347e-01</td>\n",
              "      <td>7.344209e-02</td>\n",
              "      <td>2.791687e-02</td>\n",
              "      <td>1.529375e-02</td>\n",
              "      <td>6.262463e-03</td>\n",
              "      <td>1.921075e-03</td>\n",
              "      <td>4.226996e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.022289</td>\n",
              "      <td>0.851616</td>\n",
              "      <td>1.052545e-01</td>\n",
              "      <td>1.504655e-02</td>\n",
              "      <td>3.574800e-03</td>\n",
              "      <td>1.223628e-03</td>\n",
              "      <td>6.423246e-04</td>\n",
              "      <td>2.575669e-04</td>\n",
              "      <td>7.839075e-05</td>\n",
              "      <td>1.720976e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.999969</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>8.642356e-08</td>\n",
              "      <td>1.085965e-08</td>\n",
              "      <td>2.531914e-09</td>\n",
              "      <td>8.624932e-10</td>\n",
              "      <td>4.519073e-10</td>\n",
              "      <td>1.810481e-10</td>\n",
              "      <td>5.508360e-11</td>\n",
              "      <td>1.209181e-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000060</td>\n",
              "      <td>0.017802</td>\n",
              "      <td>9.189916e-02</td>\n",
              "      <td>2.007258e-01</td>\n",
              "      <td>2.307799e-01</td>\n",
              "      <td>1.835133e-01</td>\n",
              "      <td>1.565654e-01</td>\n",
              "      <td>8.350112e-02</td>\n",
              "      <td>2.863754e-02</td>\n",
              "      <td>6.515471e-03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85f7ecc5-be37-4a5a-a4dd-893895175ebb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-85f7ecc5-be37-4a5a-a4dd-893895175ebb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-85f7ecc5-be37-4a5a-a4dd-893895175ebb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuFGIJZvymSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0077a34-840f-4892-9f04-26bd3841e5a0"
      },
      "source": [
        "# Check that probabilities all sum to 1 - looks good!\n",
        "probs_df.sum(axis = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1.0\n",
              "1       1.0\n",
              "2       1.0\n",
              "3       1.0\n",
              "4       1.0\n",
              "       ... \n",
              "9995    1.0\n",
              "9996    1.0\n",
              "9997    1.0\n",
              "9998    1.0\n",
              "9999    1.0\n",
              "Length: 10000, dtype: float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZmVlStOItF8"
      },
      "source": [
        "### Label prediction\n",
        "\n",
        "This notebook shows two ways of calculating predicted labels. We can take the highest probability label (first method) or we can choose the highest label with Pr(Y > label) > 50%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA344vSf782T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "816425ff-5ffc-4134-a2e4-7456d417b80d"
      },
      "source": [
        "# Probs to labels\n",
        "labels = probs_df.idxmax(axis = 1)\n",
        "labels.values"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8, 2, 1, ..., 4, 6, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0Bbs1tb8uh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ce7c6f5-109b-4184-e94d-ac1f2249e61f"
      },
      "source": [
        "import numpy as np\n",
        "# What is our accuracy? Around 64%.\n",
        "np.mean(labels == mnist_labels_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.606"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAUaY171_c22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2247b9a2-e9ac-40ec-89d9-58c453b58bf1"
      },
      "source": [
        "from scipy import special\n",
        "\n",
        "# Compare to logit-based cumulative probs\n",
        "cum_probs = pd.DataFrame(ordinal_logits).apply(special.expit)\n",
        "cum_probs.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.999980</td>\n",
              "      <td>0.997417</td>\n",
              "      <td>0.985583</td>\n",
              "      <td>9.466467e-01</td>\n",
              "      <td>8.770849e-01</td>\n",
              "      <td>7.482002e-01</td>\n",
              "      <td>5.185375e-01</td>\n",
              "      <td>2.242754e-01</td>\n",
              "      <td>4.152207e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.998893</td>\n",
              "      <td>0.871811</td>\n",
              "      <td>0.546330</td>\n",
              "      <td>2.381226e-01</td>\n",
              "      <td>1.116614e-01</td>\n",
              "      <td>4.973859e-02</td>\n",
              "      <td>1.861846e-02</td>\n",
              "      <td>5.067059e-03</td>\n",
              "      <td>7.625239e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.994172</td>\n",
              "      <td>0.562448</td>\n",
              "      <td>0.185410</td>\n",
              "      <td>5.577876e-02</td>\n",
              "      <td>2.320635e-02</td>\n",
              "      <td>9.796135e-03</td>\n",
              "      <td>3.572982e-03</td>\n",
              "      <td>9.616650e-04</td>\n",
              "      <td>1.442121e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000886</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>3.069660e-07</td>\n",
              "      <td>1.234523e-07</td>\n",
              "      <td>5.140741e-08</td>\n",
              "      <td>1.863292e-08</td>\n",
              "      <td>5.001923e-09</td>\n",
              "      <td>7.494793e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.999716</td>\n",
              "      <td>0.963607</td>\n",
              "      <td>0.824205</td>\n",
              "      <td>5.489042e-01</td>\n",
              "      <td>3.285749e-01</td>\n",
              "      <td>1.692839e-01</td>\n",
              "      <td>6.878123e-02</td>\n",
              "      <td>1.944230e-02</td>\n",
              "      <td>2.962163e-03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2  ...             6             7             8\n",
              "0  0.999980  0.997417  0.985583  ...  5.185375e-01  2.242754e-01  4.152207e-02\n",
              "1  0.998893  0.871811  0.546330  ...  1.861846e-02  5.067059e-03  7.625239e-04\n",
              "2  0.994172  0.562448  0.185410  ...  3.572982e-03  9.616650e-04  1.442121e-04\n",
              "3  0.000886  0.000007  0.000001  ...  1.863292e-08  5.001923e-09  7.494793e-10\n",
              "4  0.999716  0.963607  0.824205  ...  6.878123e-02  1.944230e-02  2.962163e-03\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ67xh03JOii"
      },
      "source": [
        "Now we should try another option, which is used in the Cao et al. paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNKZU84UBE7s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69240d07-3904-4e52-bdad-0c7af4de9696"
      },
      "source": [
        "# Calculate the labels using the style of Cao et al.\n",
        "labels2 = cum_probs.apply(lambda x: x > 0.5).sum(axis = 1)\n",
        "labels2.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    7\n",
              "1    3\n",
              "2    2\n",
              "3    0\n",
              "4    4\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f-7BfbYBqSN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "543e6352-4d53-4b17-cdb5-a20de35361a3"
      },
      "source": [
        "# What is the accuracy of these labels? About 66%.\n",
        "np.mean(labels2 == mnist_labels_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5815"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGlY8HecDFPO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25513886-98f5-4e5d-a50b-74b089b5e824"
      },
      "source": [
        "# More often than not these are the same, but still a lot of discrepancy.\n",
        "np.mean(labels == labels2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6844"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OemBBdUmI6TI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b74a5166-ce65-4bdc-b528-67aa76577c27"
      },
      "source": [
        "print(\"Mean absolute label error version 1:\", np.mean(np.abs(labels - mnist_labels_test)))\n",
        "print(\"Mean absolute label error version 2:\", np.mean(np.abs(labels2 - mnist_labels_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean absolute label error version 1: 0.6596\n",
            "Mean absolute label error version 2: 0.5864\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCnAaNG_GSTB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71d06230-cfb3-4725-c64d-981c950e6c2f"
      },
      "source": [
        "mnist_labels_test[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, 0, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rqIEyvQGUhd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc9fb6f1-dbed-467c-dac4-13a5d5f58378"
      },
      "source": [
        "# The output layer is the last layer in the model.\n",
        "last_layer = len(model.layers) - 1\n",
        "\n",
        "# Check bias terms: these should be in descending order.\n",
        "model.layers[last_layer].get_weights()[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8.1811285 ,  3.2930422 ,  1.5618263 ,  0.21297182, -0.6979102 ,\n",
              "       -1.5739838 , -2.588836  , -3.903943  , -5.8021417 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ywy-AbOYJZLg"
      },
      "source": [
        "Plot the bias terms to visually confirm that they are monotonically descending."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EggK0Blooy8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "8ea4591c-9f6e-424b-eb0c-18b70a53dda9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.plot(model.layers[last_layer].get_weights()[1])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DpYEPQI6-gW"
      },
      "source": [
        "### Importance weights customization\n",
        "\n",
        "A quick example to show how the importance weights can be customized. One might want to use the formula from the paper to more thoroughly calculate customized weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STwPQdgHNne4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ec43262-d984-4455-9649-715c927a976c"
      },
      "source": [
        "model = create_model(num_classes = NUM_CLASSES)\n",
        "model.summary()\n",
        "\n",
        "# We have num_classes - 1 outputs (cumulative logits), so there are 9 elements\n",
        "# in the importance vector to customize.\n",
        "importance_weights = [1., 1., 0.5, 0.5, 0.5, 1., 1., 0.1, 0.1]\n",
        "loss_fn = coral.OrdinalCrossEntropy(NUM_CLASSES, importance_weights = importance_weights)\n",
        "\n",
        "model.compile(tf.keras.optimizers.Adam(lr = learning_rate), loss = loss_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_2 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 32)                4128      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "coral_ordinal_2 (CoralOrdina (None, 9)                 41        \n",
            "=================================================================\n",
            "Total params: 104,649\n",
            "Trainable params: 104,649\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73UOIams7TI_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd1293cf-f2eb-4bd1-fabb-53fe2860c84b"
      },
      "source": [
        "%%time\n",
        "\n",
        "history = model.fit(dataset, epochs = num_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "430/430 [==============================] - 20s 44ms/step - loss: 3.9555\n",
            "Epoch 2/2\n",
            "430/430 [==============================] - 19s 44ms/step - loss: 1.4824\n",
            "CPU times: user 57.9 s, sys: 9.56 s, total: 1min 7s\n",
            "Wall time: 39 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJSm-gbwxTKt"
      },
      "source": [
        "## Amazon reviews and 5-star ratings\n",
        "\n",
        "Amazon review data via https://nijianmo.github.io/amazon/index.html#subsets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSdEFFwfoZL_"
      },
      "source": [
        "!wget -qq http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Prime_Pantry_5.json.gz "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vHiq67ioiUa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c779bee-2721-4c1a-c7e4-8dd4e0cec8ec"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import json\n",
        "import gzip\n",
        "import pandas as pd\n",
        "from urllib.request import urlopen\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "data = []\n",
        "with gzip.open('Prime_Pantry_5.json.gz') as f:\n",
        "    for l in f:\n",
        "        data.append(json.loads(l.strip()))\n",
        "\n",
        "df = pd.DataFrame.from_dict(data)\n",
        "df = df[['overall', 'reviewText']]\n",
        "\n",
        "# There is a large amount of duplicate text in here, possibly due to paid/fraudulent reviews.\n",
        "df.drop_duplicates(\"reviewText\", inplace = True)\n",
        "\n",
        "# Some of the text is blank, which causes an obscure error about floating point conversion.\n",
        "df.dropna(inplace = True)\n",
        "\n",
        "print(len(df))\n",
        "print(df.head())\n",
        "\n",
        "outcome_col = \"overall\"\n",
        "text_col = \"reviewText\"\n",
        "\n",
        "# We subtract the minimum value from the outcomes so that they start at 0.\n",
        "df[outcome_col] = df[outcome_col].values - df[outcome_col].min()\n",
        "\n",
        "print(\"\\n\", df.overall.value_counts())\n",
        "\n",
        "# TODO: define automatically based on the number of unique values in the outcome variable.\n",
        "num_classes = 5"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99025\n",
            "   overall                                         reviewText\n",
            "0      4.0  I purchased this Saran premium plastic wrap af...\n",
            "1      5.0  I am an avid cook and baker.  Saran Premium Pl...\n",
            "2      5.0  Good wrap, keeping it in the fridge makes it e...\n",
            "3      4.0  I prefer Saran wrap over other brands. It does...\n",
            "4      5.0                                             Thanks\n",
            "\n",
            " 4.0    69812\n",
            "3.0    15294\n",
            "2.0     7664\n",
            "1.0     3342\n",
            "0.0     2913\n",
            "Name: overall, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrGlqgv7tv0A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2efbfb4-7c9d-4c83-fc81-f87e4f0b5e58"
      },
      "source": [
        "# Train/Test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "text_train, text_test, labels_train, labels_test = \\\n",
        "  train_test_split(df[text_col].values, df[outcome_col].values, test_size = 10000, random_state = 1)\n",
        "\n",
        "print(\"Training text shape:\", text_train.shape)\n",
        "print(\"Training labels shape:\", labels_train.shape)\n",
        "print(\"Testing text shape:\", text_test.shape)\n",
        "print(\"Testing labels shape:\", labels_test.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training text shape: (89025,)\n",
            "Training labels shape: (89025,)\n",
            "Testing text shape: (10000,)\n",
            "Testing labels shape: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF48EdMZuTxk"
      },
      "source": [
        "### Universal Sentence Encoder model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOqeIkoJuWcD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11581a98-b7ff-4fd2-f818-0997c5d9f5dc"
      },
      "source": [
        "%%time\n",
        "# This takes 20 - 30 seconds.\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Clear our GPU memory to stay efficient.\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "input_text = tf.keras.layers.Input(shape = [], dtype = tf.string, name = 'input_text')\n",
        "\n",
        "model_url = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")\n",
        "\n",
        "base_model = hub.KerasLayer(model_url, input_shape = [],\n",
        "                            dtype = tf.string,\n",
        "                            trainable = False)\n",
        "                            \n",
        "embedded = base_model(input_text)\n",
        "\n",
        "x = tf.keras.layers.Dense(64, activation = 'relu')(embedded)\n",
        "x = tf.keras.layers.Dropout(0.1)(x)\n",
        "output = coral.CoralOrdinal(num_classes)(x) \n",
        "\n",
        "model = tf.keras.Model(inputs = input_text, outputs = output)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_text (InputLayer)     [(None,)]                 0         \n",
            "                                                                 \n",
            " keras_layer (KerasLayer)    (None, 512)               147354880 \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                32832     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " coral_ordinal (CoralOrdinal  (None, 4)                68        \n",
            " )                                                               \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 147,387,780\n",
            "Trainable params: 32,900\n",
            "Non-trainable params: 147,354,880\n",
            "_________________________________________________________________\n",
            "CPU times: user 31.7 s, sys: 3.79 s, total: 35.5 s\n",
            "Wall time: 36.7 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmMr5L_u_o64",
        "outputId": "a749740a-812c-4d3b-8021-576b396b844f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.compile(loss = coral.OrdinalCrossEntropy(num_classes),\n",
        "              metrics = [coral.MeanAbsoluteErrorLabels()],\n",
        "              optimizer = tf.keras.optimizers.Adam(lr = 0.001))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwNLAJg33tc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78c5bcd5-9c73-41d2-94d8-31d7737ae9e0"
      },
      "source": [
        "# Encode a test string and take a look at the first ten dimensions.\n",
        "base_model(np.array([\"test_string\"])).numpy()[0, :10]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.01035028,  0.00395392, -0.04288317,  0.0048328 , -0.07732296,\n",
              "       -0.06699762,  0.01624425, -0.01737378, -0.00085807,  0.01084492],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85MsPnRTxPEz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f32aa095-7719-402e-be4f-5e8df19aa044"
      },
      "source": [
        "%%time\n",
        "\n",
        "history = model.fit(x = text_train,\n",
        "                    y = labels_train,\n",
        "                    epochs = 5,\n",
        "                    # 128 and 512 cause out-of-memory errors. But strange that it happens after ~10 epochs.\n",
        "                    batch_size = 32, \n",
        "                    validation_split = 0.2,\n",
        "                    callbacks = [tf.keras.callbacks.EarlyStopping(patience = 2,\n",
        "                                                                  min_delta = 0.001,\n",
        "                                                                  restore_best_weights = True)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "2224/2226 [============================>.] - ETA: 0s - loss: 1.0067 - mean_absolute_error_labels: 0.3948"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXFi2qXPlehY"
      },
      "source": [
        "### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3ocFVWnldzF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51ec020a-92ac-4999-bb33-444e1390a9a4"
      },
      "source": [
        "model.evaluate(text_test, labels_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 21s 66ms/step - loss: 0.7962 - mean_absolute_error_labels: 0.3195\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7962134480476379, 0.3194888234138489]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqSBmDgXxkFb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b12ffee-3bd5-4645-edcc-a5317203b821"
      },
      "source": [
        "# Generate predictions - initially these are cumulative logits.\n",
        "preds = model.predict(text_test)\n",
        "print(preds)\n",
        "# Convert cumulative logits to probabilities for each class aka rank or label.\n",
        "probs = pd.DataFrame(coral.ordinal_softmax(preds).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 8.118758    6.815898    5.2418857   3.5594192 ]\n",
            " [ 4.1327972   2.829937    1.2559245  -0.4265418 ]\n",
            " [ 6.450637    5.147777    3.5737643   1.8912982 ]\n",
            " ...\n",
            " [ 4.368989    3.066129    1.4921162  -0.19034994]\n",
            " [ 6.744893    5.442033    3.8680203   2.185554  ]\n",
            " [ 7.300754    5.9978943   4.4238815   2.741415  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvD7ak27yA26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb188fda-8d46-463e-b2de-30e75e8d694b"
      },
      "source": [
        "print(probs.head(10))\n",
        "print(labels_test[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0         1         2         3         4\n",
            "0  0.000298  0.000797  0.004167  0.022406  0.972332\n",
            "1  0.015785  0.039943  0.165949  0.383371  0.394952\n",
            "2  0.001577  0.004202  0.021506  0.103812  0.868903\n",
            "3  0.009369  0.024264  0.110174  0.330825  0.525368\n",
            "4  0.004581  0.012073  0.058905  0.229821  0.694620\n",
            "5  0.000422  0.001130  0.005892  0.031333  0.961223\n",
            "6  0.000875  0.002337  0.012099  0.061866  0.922824\n",
            "7  0.371062  0.313582  0.228227  0.069693  0.017435\n",
            "8  0.003381  0.008949  0.044496  0.187928  0.755245\n",
            "9  0.001191  0.003179  0.016373  0.081541  0.897715\n",
            "[4. 1. 4. 2. 4. 4. 4. 1. 4. 4.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNYR4nOjDJt_"
      },
      "source": [
        "### Evaluate accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZzpmNSGxmJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34060a01-aa85-4eb5-8de7-bfebd8c482fb"
      },
      "source": [
        "# Evaluate accuracy and mean absolute error\n",
        "labels_v1 = probs.idxmax(axis = 1)\n",
        "print(\"Accuracy of label version 1:\", np.mean(labels_v1 == labels_test))\n",
        "\n",
        "from scipy import special\n",
        "\n",
        "# Compare to logit-based cumulative probs\n",
        "cum_probs = pd.DataFrame(preds).apply(special.expit)\n",
        "# Calculate the labels using the style of Cao et al.\n",
        "labels_v2 = cum_probs.apply(lambda x: x > 0.5).sum(axis = 1)\n",
        "print(\"Accuracy of label version 2:\", np.mean(labels_v2 == labels_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of label version 1: 0.7454\n",
            "Accuracy of label version 2: 0.74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYKpSMosDMuq"
      },
      "source": [
        "### Evaluate mean absolute label error\n",
        "\n",
        "This is effectively an ordinal version of 1 - accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJZNCzwfGqC0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b6268cf-56f7-4892-e6c4-8f260f4a03c1"
      },
      "source": [
        "# These do not correspond with what we get from the model evaluation. Something must be off in one of these.\n",
        "print(\"Mean absolute label error version 1:\", np.mean(np.abs(labels_v1 - labels_test)))\n",
        "print(\"Mean absolute label error version 2:\", np.mean(np.abs(labels_v2 - labels_test)))\n",
        "\n",
        "print(\"Root mean squared label error version 1:\", np.sqrt(np.mean(np.square(labels_v1 - labels_test))))\n",
        "print(\"Root mean squared label error version 2:\", np.sqrt(np.mean(np.square(labels_v2 - labels_test))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean absolute label error version 1: 0.3286\n",
            "Mean absolute label error version 2: 0.3197\n",
            "Root mean squared label error version 1: 0.7128814768248646\n",
            "Root mean squared label error version 2: 0.6803675477269621\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddSncBedI37-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "22fc9192-5669-400d-e5b0-91de61916535"
      },
      "source": [
        "# Review how absolute error is calculated for ordinal labels:\n",
        "pd.DataFrame({\"true\": labels_test, \"pred_v2\": labels_v1, \"abs\": labels_v2 - labels_test}).head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>true</th>\n",
              "      <th>pred_v2</th>\n",
              "      <th>abs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   true  pred_v2  abs\n",
              "0   4.0        4  0.0\n",
              "1   1.0        4  2.0\n",
              "2   4.0        4  0.0\n",
              "3   2.0        4  2.0\n",
              "4   4.0        4  0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    }
  ]
}